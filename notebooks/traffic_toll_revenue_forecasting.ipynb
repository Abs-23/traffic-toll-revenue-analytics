{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "364fa61a-9f9f-49d4-a713-fa7c9ceb596a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/Volumes/traffic_lab/raw/traffic_files/Metro_Interstate_Traffic_Volume.csv</td><td>Metro_Interstate_Traffic_Volume.csv</td><td>3237208</td><td>1764799651000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/Volumes/traffic_lab/raw/traffic_files/Metro_Interstate_Traffic_Volume.csv",
         "Metro_Interstate_Traffic_Volume.csv",
         3237208,
         1764799651000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(\"USE CATALOG traffic_lab\")\n",
    "spark.sql(\"USE raw\")\n",
    "\n",
    "# List files in the volume to see the path\n",
    "display(dbutils.fs.ls(\"/Volumes/traffic_lab/raw/traffic_files/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fdca3b6-325b-4825-aab5-e91eaaee4313",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"/Volumes/traffic_lab/raw/traffic_files/Metro_Interstate_Traffic_Volume.csv\"\n",
    "\n",
    "df_raw = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .csv(file_path)\n",
    ")\n",
    "\n",
    "df_raw.write.mode(\"overwrite\").saveAsTable(\"raw.metro_interstate_raw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ce6427e-fdc1-4664-9353-a1012c6e6d8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|COUNT(*)|\n+--------+\n|   48204|\n+--------+\n\n+-------+------+-------+-------+----------+------------+-------------------+-------------------+--------------+\n|holiday|  temp|rain_1h|snow_1h|clouds_all|weather_main|weather_description|          date_time|traffic_volume|\n+-------+------+-------+-------+----------+------------+-------------------+-------------------+--------------+\n|   None|288.28|    0.0|    0.0|        40|      Clouds|   scattered clouds|2012-10-02 09:00:00|          5545|\n|   None|289.36|    0.0|    0.0|        75|      Clouds|      broken clouds|2012-10-02 10:00:00|          4516|\n|   None|289.58|    0.0|    0.0|        90|      Clouds|    overcast clouds|2012-10-02 11:00:00|          4767|\n|   None|290.13|    0.0|    0.0|        90|      Clouds|    overcast clouds|2012-10-02 12:00:00|          5026|\n|   None|291.14|    0.0|    0.0|        75|      Clouds|      broken clouds|2012-10-02 13:00:00|          4918|\n+-------+------+-------+-------+----------+------------+-------------------+-------------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) FROM raw.metro_interstate_raw\").show()\n",
    "spark.sql(\"SELECT * FROM raw.metro_interstate_raw LIMIT 5\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc2dab8b-9167-42db-b6fa-0099aaa18370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+-------+\n|           col_name|data_type|comment|\n+-------------------+---------+-------+\n|            holiday|   string|   NULL|\n|               temp|   double|   NULL|\n|            rain_1h|   double|   NULL|\n|            snow_1h|   double|   NULL|\n|         clouds_all|      int|   NULL|\n|       weather_main|   string|   NULL|\n|weather_description|   string|   NULL|\n|          date_time|timestamp|   NULL|\n|     traffic_volume|      int|   NULL|\n+-------------------+---------+-------+\n\n+-------------------+-------------------+---------+\n|             min_ts|             max_ts|row_count|\n+-------------------+-------------------+---------+\n|2012-10-02 09:00:00|2018-09-30 23:00:00|    48204|\n+-------------------+-------------------+---------+\n\n+-----------+------------------+\n|hour_of_day|        avg_volume|\n+-----------+------------------+\n|          0| 834.7810505645557|\n|          1|  516.448999511957|\n|          2|388.35364041604754|\n|          3| 371.0908641975309|\n|          4| 702.5518890483022|\n|          5| 2094.573436742608|\n|          6| 4140.503593675132|\n|          7| 4740.181337181337|\n|          8| 4587.497115384615|\n|          9| 4385.277502477701|\n|         10| 4184.665543792108|\n|         11|4465.8775614754095|\n|         12| 4718.293094629156|\n|         13| 4714.940682414698|\n|         14| 4931.888776028441|\n|         15|  5240.52430196484|\n|         16| 5663.756539235413|\n|         17| 5310.076047594413|\n|         18| 4263.718529707956|\n|         19|  3276.39418663947|\n+-----------+------------------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"USE CATALOG traffic_lab\")\n",
    "spark.sql(\"USE raw\")\n",
    "\n",
    "spark.sql(\"DESCRIBE TABLE metro_interstate_raw\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "  MIN(date_time) AS min_ts,\n",
    "  MAX(date_time) AS max_ts,\n",
    "  COUNT(*) AS row_count\n",
    "FROM metro_interstate_raw\n",
    "\"\"\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "  HOUR(date_time) AS hour_of_day,\n",
    "  AVG(traffic_volume) AS avg_volume\n",
    "FROM metro_interstate_raw\n",
    "GROUP BY HOUR(date_time)\n",
    "ORDER BY hour_of_day\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "075c35c1-c190-4a53-bccb-8824bce97bfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE silver.metro_interstate_hourly AS\n",
    "SELECT\n",
    "  date_time,\n",
    "  traffic_volume,\n",
    "  HOUR(date_time) AS hour_of_day,\n",
    "  DAYOFWEEK(date_time) AS day_of_week,\n",
    "  MONTH(date_time) AS month,\n",
    "  CASE WHEN DAYOFWEEK(date_time) IN (1,7) THEN 1 ELSE 0 END AS is_weekend\n",
    "FROM raw.metro_interstate_raw\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13f9497c-d6ec-451c-bf02-96fa22a5bc8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+-----------+-----------+-----+----------+\n|          date_time|traffic_volume|hour_of_day|day_of_week|month|is_weekend|\n+-------------------+--------------+-----------+-----------+-----+----------+\n|2012-10-02 09:00:00|          5545|          9|          3|   10|         0|\n|2012-10-02 10:00:00|          4516|         10|          3|   10|         0|\n|2012-10-02 11:00:00|          4767|         11|          3|   10|         0|\n|2012-10-02 12:00:00|          5026|         12|          3|   10|         0|\n|2012-10-02 13:00:00|          4918|         13|          3|   10|         0|\n+-------------------+--------------+-----------+-----------+-----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM silver.metro_interstate_hourly LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81529c62-afe0-4598-9038-26851ac6d318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+-------+\n|           col_name|data_type|comment|\n+-------------------+---------+-------+\n|            holiday|   string|   NULL|\n|               temp|   double|   NULL|\n|            rain_1h|   double|   NULL|\n|            snow_1h|   double|   NULL|\n|         clouds_all|      int|   NULL|\n|       weather_main|   string|   NULL|\n|weather_description|   string|   NULL|\n|          date_time|timestamp|   NULL|\n|     traffic_volume|      int|   NULL|\n+-------------------+---------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE TABLE raw.metro_interstate_raw\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34924237-ea84-42ea-8692-0c861721b086",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+-----------+-----------+-----+----------+-------+------+-------+-------+----------+------------+\n|          date_time|traffic_volume|hour_of_day|day_of_week|month|is_weekend|holiday|  temp|rain_1h|snow_1h|clouds_all|weather_main|\n+-------------------+--------------+-----------+-----------+-----+----------+-------+------+-------+-------+----------+------------+\n|2012-10-02 09:00:00|          5545|          9|          3|   10|         0|   None|288.28|    0.0|    0.0|        40|      Clouds|\n|2012-10-02 10:00:00|          4516|         10|          3|   10|         0|   None|289.36|    0.0|    0.0|        75|      Clouds|\n|2012-10-02 11:00:00|          4767|         11|          3|   10|         0|   None|289.58|    0.0|    0.0|        90|      Clouds|\n|2012-10-02 12:00:00|          5026|         12|          3|   10|         0|   None|290.13|    0.0|    0.0|        90|      Clouds|\n|2012-10-02 13:00:00|          4918|         13|          3|   10|         0|   None|291.14|    0.0|    0.0|        75|      Clouds|\n+-------------------+--------------+-----------+-----------+-----+----------+-------+------+-------+-------+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE silver.metro_interstate_hourly AS\n",
    "SELECT\n",
    "  date_time,\n",
    "  traffic_volume,\n",
    "  HOUR(date_time) AS hour_of_day,\n",
    "  DAYOFWEEK(date_time) AS day_of_week,\n",
    "  MONTH(date_time) AS month,\n",
    "  CASE WHEN DAYOFWEEK(date_time) IN (1,7) THEN 1 ELSE 0 END AS is_weekend,\n",
    "  holiday,\n",
    "  temp,\n",
    "  rain_1h,\n",
    "  snow_1h,\n",
    "  clouds_all,\n",
    "  weather_main\n",
    "FROM raw.metro_interstate_raw\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM silver.metro_interstate_hourly LIMIT 5\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79fd436a-1da4-49fd-bfb3-d1f022e53424",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+--------------------+------------------+-----------+-----------+------------------+-----------+\n|      date|avg_traffic_volume|total_traffic_volume|          avg_temp|max_rain_1h|max_snow_1h|    avg_clouds_all|any_holiday|\n+----------+------------------+--------------------+------------------+-----------+-----------+------------------+-----------+\n|2012-10-02| 4219.266666666666|               63289|290.40333333333336|        0.0|        0.0|29.133333333333333|       None|\n|2012-10-03|           3317.25|               66345|          286.4135|        0.0|        0.0|              3.85|       None|\n|2012-10-04|3747.4583333333335|               89939|          289.3575|        0.0|        0.0|16.708333333333332|       None|\n|2012-10-05| 4242.545454545455|               93336| 282.0781818181818|        0.0|        0.0|              75.0|       None|\n|2012-10-06|3256.9565217391305|               74910|277.74608695652176|        0.0|        0.0| 61.65217391304348|       None|\n+----------+------------------+--------------------+------------------+-----------+-----------+------------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE gold.metro_interstate_daily AS\n",
    "SELECT\n",
    "  DATE(date_time) AS date,\n",
    "  AVG(traffic_volume) AS avg_traffic_volume,\n",
    "  SUM(traffic_volume) AS total_traffic_volume,\n",
    "  AVG(temp) AS avg_temp,\n",
    "  MAX(rain_1h) AS max_rain_1h,\n",
    "  MAX(snow_1h) AS max_snow_1h,\n",
    "  AVG(clouds_all) AS avg_clouds_all,\n",
    "  MAX(holiday) AS any_holiday \n",
    "FROM silver.metro_interstate_hourly\n",
    "GROUP BY DATE(date_time)\n",
    "ORDER BY date\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM gold.metro_interstate_daily LIMIT 5\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f95112ee-234f-4fa2-9d89-aecefd37f056",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- date: date (nullable = true)\n |-- avg_traffic_volume: double (nullable = true)\n |-- total_traffic_volume: long (nullable = true)\n |-- avg_temp: double (nullable = true)\n |-- max_rain_1h: double (nullable = true)\n |-- max_snow_1h: double (nullable = true)\n |-- avg_clouds_all: double (nullable = true)\n |-- any_holiday: string (nullable = true)\n\n+----------+------------------+--------------------+------------------+-----------+-----------+------------------+-----------+\n|      date|avg_traffic_volume|total_traffic_volume|          avg_temp|max_rain_1h|max_snow_1h|    avg_clouds_all|any_holiday|\n+----------+------------------+--------------------+------------------+-----------+-----------+------------------+-----------+\n|2012-10-02| 4219.266666666666|               63289|290.40333333333336|        0.0|        0.0|29.133333333333333|       None|\n|2012-10-03|           3317.25|               66345|          286.4135|        0.0|        0.0|              3.85|       None|\n|2012-10-04|3747.4583333333335|               89939|          289.3575|        0.0|        0.0|16.708333333333332|       None|\n|2012-10-05| 4242.545454545455|               93336| 282.0781818181818|        0.0|        0.0|              75.0|       None|\n|2012-10-06|3256.9565217391305|               74910|277.74608695652176|        0.0|        0.0| 61.65217391304348|       None|\n+----------+------------------+--------------------+------------------+-----------+-----------+------------------+-----------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"USE CATALOG traffic_lab\")\n",
    "spark.sql(\"USE gold\")\n",
    "\n",
    "df_daily = spark.table(\"gold.metro_interstate_daily\").orderBy(\"date\")\n",
    "df_daily.printSchema()\n",
    "df_daily.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c48d7520-2811-45b1-9a0f-a7d7da1de294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pdf = df_daily.toPandas()\n",
    "pdf = pdf.dropna()\n",
    "\n",
    "# Simple time-based split: first 80% train, last 20% test\n",
    "split_idx = int(len(pdf) * 0.8)\n",
    "train = pdf.iloc[:split_idx]\n",
    "test = pdf.iloc[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42a451e4-8f8e-42f4-8608-4975965d1675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"avg_temp\",\n",
    "    \"max_rain_1h\",\n",
    "    \"max_snow_1h\",\n",
    "    \"avg_clouds_all\"\n",
    "]\n",
    "\n",
    "X = pdf[feature_cols]\n",
    "y = pdf[\"total_traffic_volume\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff332a52-dd71-4806-9d97-d16456f0e0d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train[feature_cols], test[feature_cols]\n",
    "y_train, y_test = train[\"total_traffic_volume\"], test[\"total_traffic_volume\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcf0349c-de47-47ff-8bb1-50cff74e9f40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(23277.09252688172, -0.1704175949964637)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae, r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75d571d8-f1ee-4ec5-b303-379978d0e327",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We used only weather features (avg_temp, max_rain_1h, etc.). That ignores the biggest drivers of traffic: time patterns (month, weekday/weekend, seasonality). So the model can’t learn “Mondays are heavier than Sundays,” etc., which explains the negative R².\n",
    "\n",
    "Next step: add time features into the model\n",
    "Let’s bring in month and a simplified is_weekend into the gold table, then into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6ed8590-73b4-4e69-be65-8f1db07e5de7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE traffic_lab.gold.metro_interstate_daily AS\n",
    "SELECT\n",
    "  DATE(date_time) AS date,\n",
    "  AVG(traffic_volume) AS avg_traffic_volume,\n",
    "  SUM(traffic_volume) AS total_traffic_volume,\n",
    "  AVG(temp) AS avg_temp,\n",
    "  MAX(rain_1h) AS max_rain_1h,\n",
    "  MAX(snow_1h) AS max_snow_1h,\n",
    "  AVG(clouds_all) AS avg_clouds_all,\n",
    "  MAX(holiday) AS any_holiday,\n",
    "  MAX(MONTH(date_time)) AS month,\n",
    "  MAX(CASE WHEN DAYOFWEEK(date_time) IN (1,7) THEN 1 ELSE 0 END) AS is_weekend\n",
    "FROM  traffic_lab.silver.metro_interstate_hourly\n",
    "GROUP BY DATE(date_time)\n",
    "ORDER BY date\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89bc7e2f-1f52-4ef8-ab56-980b43e12a82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_daily = spark.table(\"traffic_lab.gold.metro_interstate_daily\").orderBy(\"date\")\n",
    "pdf = df_daily.toPandas().dropna()\n",
    "\n",
    "split_idx = int(len(pdf) * 0.8)\n",
    "train = pdf.iloc[:split_idx]\n",
    "test = pdf.iloc[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81818dfa-e9a4-401f-80ac-cbb88cf37e2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"avg_temp\",\n",
    "    \"max_rain_1h\",\n",
    "    \"max_snow_1h\",\n",
    "    \"avg_clouds_all\",\n",
    "    \"month\",\n",
    "    \"is_weekend\"\n",
    "]\n",
    "\n",
    "X_train, X_test = train[feature_cols], test[feature_cols]\n",
    "y_train, y_test = train[\"total_traffic_volume\"], test[\"total_traffic_volume\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20f3324e-665f-43e7-9a73-ba90e84d4810",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(19405.458911290323, 0.08206851625811507)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae, r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78b8aaa0-51e9-4ebf-bb82-b7c5a9961347",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    ": Adding tolls and revenue logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "010421c3-2259-4cc1-98aa-04d012f4c754",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Predict for all days (for scenario analysis)\n",
    "X_all = pdf[feature_cols]\n",
    "pdf[\"predicted_volume\"] = model.predict(X_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e452e9fb-8cbf-493c-be53-d7d130b3e895",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "car_share = 0.85\n",
    "truck_share = 0.15\n",
    "\n",
    "base_car_toll = 3.0\n",
    "base_truck_toll = 7.0\n",
    "\n",
    "pdf[\"cars_base\"] = pdf[\"predicted_volume\"] * car_share\n",
    "pdf[\"trucks_base\"] = pdf[\"predicted_volume\"] * truck_share\n",
    "\n",
    "pdf[\"revenue_base\"] = (\n",
    "    pdf[\"cars_base\"] * base_car_toll\n",
    "    + pdf[\"trucks_base\"] * base_truck_toll\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b345486-4387-4cca-b47c-674bc5bcc2da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "weekend_factor = 1.20  # 20% higher tolls on weekends\n",
    "\n",
    "pdf[\"car_toll_weekend\"] = base_car_toll\n",
    "pdf[\"truck_toll_weekend\"] = base_truck_toll\n",
    "\n",
    "pdf.loc[pdf[\"is_weekend\"] == 1, \"car_toll_weekend\"] = base_car_toll * weekend_factor\n",
    "pdf.loc[pdf[\"is_weekend\"] == 1, \"truck_toll_weekend\"] = base_truck_toll * weekend_factor\n",
    "\n",
    "pdf[\"revenue_weekend_boost\"] = (\n",
    "    pdf[\"cars_base\"] * pdf[\"car_toll_weekend\"]\n",
    "    + pdf[\"trucks_base\"] * pdf[\"truck_toll_weekend\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "184ab6c2-439d-4751-a2b4-3b2a9831fdb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>revenue_base</th>\n",
       "      <th>revenue_weekend_boost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>2.828671e+07</td>\n",
       "      <td>2.963146e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1.025658e+08</td>\n",
       "      <td>1.071873e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>5.901039e+07</td>\n",
       "      <td>6.165319e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>5.292792e+07</td>\n",
       "      <td>5.512898e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>1.071928e+08</td>\n",
       "      <td>1.119736e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017</td>\n",
       "      <td>1.159105e+08</td>\n",
       "      <td>1.212078e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018</td>\n",
       "      <td>7.944017e+07</td>\n",
       "      <td>8.290619e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  revenue_base  revenue_weekend_boost\n",
       "0  2012  2.828671e+07           2.963146e+07\n",
       "1  2013  1.025658e+08           1.071873e+08\n",
       "2  2014  5.901039e+07           6.165319e+07\n",
       "3  2015  5.292792e+07           5.512898e+07\n",
       "4  2016  1.071928e+08           1.119736e+08\n",
       "5  2017  1.159105e+08           1.212078e+08\n",
       "6  2018  7.944017e+07           8.290619e+07"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pdf[\"year\"] = pd.to_datetime(pdf[\"date\"]).dt.year\n",
    "\n",
    "annual_rev = (\n",
    "    pdf.groupby(\"year\")[[\"revenue_base\", \"revenue_weekend_boost\"]]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "annual_rev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b83bfe19-4b17-485a-a1b1-ecf3c4bd1ac4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Why model demand response (elasticity)?\n",
    "\n",
    "In reality, drivers react when tolls change. If we increase prices, some users divert to other routes or travel at different times.  \n",
    "Ignoring this and assuming traffic volume stays fixed would **overstate** revenue gains from higher tolls.\n",
    "\n",
    "To keep the analysis realistic, I introduce a simple **price elasticity of demand**:\n",
    "\n",
    "- A 20% toll increase on weekends causes a small % drop in weekend traffic.\n",
    "- This lets me compare:\n",
    "  - Base case: flat tolls, higher volumes.\n",
    "  - Scenario: higher weekend tolls, slightly lower weekend volumes but potentially higher total revenue.\n",
    "\n",
    "This is closer to how Traffic & Revenue (T&R) analysts evaluate pricing strategies in practice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cf0ff56-b7df-4513-bad8-96b9262a6ece",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "elasticity = -0.2  # demand elasticity wrt price\n",
    "\n",
    "# % change in toll for weekend days (0.20 = +20%)\n",
    "pdf[\"pct_change_toll\"] = 0.0\n",
    "pdf.loc[pdf[\"is_weekend\"] == 1, \"pct_change_toll\"] = 0.20\n",
    "\n",
    "# % change in volume = elasticity * % change in toll\n",
    "pdf[\"pct_change_volume\"] = elasticity * pdf[\"pct_change_toll\"]\n",
    "\n",
    "# Adjusted volume under weekend-boost scenario\n",
    "pdf[\"volume_weekend_elastic\"] = pdf[\"predicted_volume\"] * (1 + pdf[\"pct_change_volume\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d246bd91-38a7-4278-85b7-a69791c1cb20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "car_share = 0.85\n",
    "truck_share = 0.15\n",
    "\n",
    "# base tolls\n",
    "base_car_toll = 3.0\n",
    "base_truck_toll = 7.0\n",
    "\n",
    "# weekend tolls (same as before)\n",
    "weekend_factor = 1.20\n",
    "pdf[\"car_toll_weekend\"] = base_car_toll\n",
    "pdf[\"truck_toll_weekend\"] = base_truck_toll\n",
    "pdf.loc[pdf[\"is_weekend\"] == 1, \"car_toll_weekend\"] = base_car_toll * weekend_factor\n",
    "pdf.loc[pdf[\"is_weekend\"] == 1, \"truck_toll_weekend\"] = base_truck_toll * weekend_factor\n",
    "\n",
    "# Base scenario (unchanged)\n",
    "pdf[\"cars_base\"] = pdf[\"predicted_volume\"] * car_share\n",
    "pdf[\"trucks_base\"] = pdf[\"predicted_volume\"] * truck_share\n",
    "pdf[\"revenue_base\"] = (\n",
    "    pdf[\"cars_base\"] * base_car_toll\n",
    "    + pdf[\"trucks_base\"] * base_truck_toll\n",
    ")\n",
    "\n",
    "# Weekend-boost scenario with elasticity\n",
    "pdf[\"cars_weekend_elastic\"] = pdf[\"volume_weekend_elastic\"] * car_share\n",
    "pdf[\"trucks_weekend_elastic\"] = pdf[\"volume_weekend_elastic\"] * truck_share\n",
    "\n",
    "pdf[\"revenue_weekend_elastic\"] = (\n",
    "    pdf[\"cars_weekend_elastic\"] * pdf[\"car_toll_weekend\"]\n",
    "    + pdf[\"trucks_weekend_elastic\"] * pdf[\"truck_toll_weekend\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "571f1267-8bc9-4905-8b6f-b4ab7fc0b884",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>revenue_base</th>\n",
       "      <th>revenue_weekend_elastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>2.828671e+07</td>\n",
       "      <td>2.930872e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1.025658e+08</td>\n",
       "      <td>1.060781e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>5.901039e+07</td>\n",
       "      <td>6.101892e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>5.292792e+07</td>\n",
       "      <td>5.460073e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>1.071928e+08</td>\n",
       "      <td>1.108263e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017</td>\n",
       "      <td>1.159105e+08</td>\n",
       "      <td>1.199365e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018</td>\n",
       "      <td>7.944017e+07</td>\n",
       "      <td>8.207435e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  revenue_base  revenue_weekend_elastic\n",
       "0  2012  2.828671e+07             2.930872e+07\n",
       "1  2013  1.025658e+08             1.060781e+08\n",
       "2  2014  5.901039e+07             6.101892e+07\n",
       "3  2015  5.292792e+07             5.460073e+07\n",
       "4  2016  1.071928e+08             1.108263e+08\n",
       "5  2017  1.159105e+08             1.199365e+08\n",
       "6  2018  7.944017e+07             8.207435e+07"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf[\"year\"] = pd.to_datetime(pdf[\"date\"]).dt.year\n",
    "\n",
    "annual_rev_elastic = (\n",
    "    pdf.groupby(\"year\")[[\"revenue_base\", \"revenue_weekend_elastic\"]]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "annual_rev_elastic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39b43cba-f421-4a26-be8f-44a5ceb14626",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_path = \"/Volumes/traffic_lab/raw/traffic_files/traffic_daily_export.csv\"\n",
    "\n",
    "pdf_daily_export = pdf[[\n",
    "    \"date\",\n",
    "    \"predicted_volume\",\n",
    "    \"total_traffic_volume\",\n",
    "    \"is_weekend\",\n",
    "    \"revenue_base\",\n",
    "    \"revenue_weekend_elastic\",\n",
    "    \"year\"\n",
    "]]\n",
    "\n",
    "pdf_daily_export.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eea33df7-a4e6-4882-87ce-1fba631943ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/Volumes/traffic_lab/raw/traffic_files/Metro_Interstate_Traffic_Volume.csv</td><td>Metro_Interstate_Traffic_Volume.csv</td><td>3237208</td><td>1764799651000</td></tr><tr><td>dbfs:/Volumes/traffic_lab/raw/traffic_files/traffic_daily_export.csv</td><td>traffic_daily_export.csv</td><td>116931</td><td>1764804617000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/Volumes/traffic_lab/raw/traffic_files/Metro_Interstate_Traffic_Volume.csv",
         "Metro_Interstate_Traffic_Volume.csv",
         3237208,
         1764799651000
        ],
        [
         "dbfs:/Volumes/traffic_lab/raw/traffic_files/traffic_daily_export.csv",
         "traffic_daily_export.csv",
         116931,
         1764804617000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls(\"/Volumes/traffic_lab/raw/traffic_files/\"))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "traffic_toll_revenue_forecasting",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}